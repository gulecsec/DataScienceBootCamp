{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The livecodes of the lecture are based on the code used by the students during the challenges.\n",
    "\n",
    "We will use the **lifecycle lecture** challenge for all the livecodes of the lecture.\n",
    "\n",
    "Myriad batches:\n",
    "\n",
    "``` bash\n",
    "cd mlops-lifecycle-lecture\n",
    "```\n",
    "\n",
    "Legacy batches:\n",
    "\n",
    "``` bash\n",
    "cd data-challenges/07-ML-Ops/03-Automate-model-lifecycle/00-Lecture-livecode\n",
    "```\n",
    "\n",
    "Then use VSCode:\n",
    "\n",
    "``` bash\n",
    "code .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local and Big Query setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not already have a valid local conf in `~/.lewagon/mlops` and a valid Big Query dataset for the taxifare data, you can use the `Makefile` in order to create them.\n",
    "\n",
    "Edit the `DATASET_SIZE` and `VALIDATION_DATASET_SIZE` variables in your `.env`, then `direnv allow .` and `direnv reload`.\n",
    "\n",
    "You will be able to retrieve the latest version of the data using either:\n",
    "- `make reset_sources_all` in order to reset datasets of all sizes in local disk + Big Query\n",
    "- `make reset_sources_env` in order to reset datasets of size `DATASET_SIZE` / `VALIDATION_DATASET_SIZE` in local disk + Big Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the `.env.sample` to a `.env` file with the default parameters to:\n",
    "- Load data from Big Query\n",
    "- Store the experiment in MLflow\n",
    "- Chunk size set to 100k allows to train faster (single chunk for the training)\n",
    "\n",
    "``` bash\n",
    "LOCAL_DATA_PATH=~/.lewagon/mlops/data\n",
    "LOCAL_REGISTRY_PATH=~/.lewagon/mlops/training_outputs\n",
    "\n",
    "DATASET_SIZE=10k\n",
    "VALIDATION_DATASET_SIZE=10k\n",
    "CHUNK_SIZE=2000\n",
    "\n",
    "DATA_SOURCE=\"big query\"\n",
    "MODEL_TARGET=mlflow\n",
    "PREFECT_BACKEND=local\n",
    "\n",
    "PROJECT=le-wagon-ds\n",
    "\n",
    "DATASET=taxifare_dataset\n",
    "\n",
    "MLFLOW_TRACKING_URI=https://mlflow.lewagon.ai\n",
    "\n",
    "MLFLOW_EXPERIMENT=\"lecli #941 wagoncab\"\n",
    "MLFLOW_MODEL_NAME=wagoncab_taxifare_941\n",
    "```\n",
    "\n",
    "üö® `PROJECT`: change to your GCP project id\n",
    "\n",
    "üö® `MLFLOW_MODEL_NAME`: must not contain spaces or the prediction will not work\n",
    "\n",
    "üö® Do not forget to `direnv allow .` and `direnv reload` whenever required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**interface/main.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    preprocess()\n",
    "    preprocess(source_type='val')\n",
    "    train()\n",
    "    pred()\n",
    "    # evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ml_logic/registry.py in `save_model()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if os.environ.get(\"MODEL_TARGET\") == \"mlflow\":\n",
    "\n",
    "        print(Fore.BLUE + \"\\nSave model to mlflow...\" + Style.RESET_ALL)\n",
    "\n",
    "        mlflow_tracking_uri = os.environ.get(\"MLFLOW_TRACKING_URI\")\n",
    "        mlflow_experiment = os.environ.get(\"MLFLOW_EXPERIMENT\")\n",
    "        mlflow_model_name = os.environ.get(\"MLFLOW_MODEL_NAME\")\n",
    "\n",
    "        mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "        mlflow.set_experiment(experiment_name=mlflow_experiment)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "\n",
    "            if params is not None:\n",
    "                mlflow.log_params(params)\n",
    "\n",
    "            if metrics is not None:\n",
    "                mlflow.log_metrics(metrics)\n",
    "\n",
    "            if model is not None:\n",
    "\n",
    "                mlflow.keras.log_model(keras_model=model,\n",
    "                                       artifact_path=\"model\",\n",
    "                                       keras_module=\"tensorflow.keras\",\n",
    "                                       registered_model_name=mlflow_model_name)\n",
    "\n",
    "        print(\"\\n‚úÖ data saved to mlflow\")\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ml_logic/registry.py in `load_model()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if os.environ.get(\"MODEL_TARGET\") == \"mlflow\":\n",
    "\n",
    "        print(Fore.BLUE + \"\\nLoad model from mlflow...\" + Style.RESET_ALL)\n",
    "\n",
    "        # load model from mlflow\n",
    "        mlflow.set_tracking_uri(os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "\n",
    "        mlflow_model_name = os.environ.get(\"MLFLOW_MODEL_NAME\")\n",
    "\n",
    "        stage = \"Production\"\n",
    "\n",
    "        model_uri = f\"models:/{mlflow_model_name}/{stage}\"\n",
    "        print(f\"- uri: {model_uri}\")\n",
    "\n",
    "        try:\n",
    "            model = mlflow.keras.load_model(model_uri=model_uri)\n",
    "            print(\"\\n‚úÖ model loaded from mlflow\")\n",
    "        except:\n",
    "            print(f\"\\n‚ùå no model in stage {stage} on mlflow\")\n",
    "            return None\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Train the model:\n",
    "\n",
    "``` bash\n",
    "make run_all\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üö® In **MLflow**, set the latest trained model in **Production** so that it can be retrieved by `evaluate()`\n",
    "\n",
    "Create `workflow.py` and fill its content.\n",
    "\n",
    "üëâ Run the code with `python -m taxifare.interface.workflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**interface/workflow.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxifare.interface.main import (preprocess, train, evaluate)\n",
    "\n",
    "from colorama import Fore, Style\n",
    "\n",
    "\n",
    "def eval_perf(next_row):\n",
    "\n",
    "    # evaluate latest production model on new data\n",
    "    past_perf = evaluate()\n",
    "\n",
    "    print(Fore.GREEN + \"\\nüî• Ran task: EVAL PERF:\" + Style.RESET_ALL\n",
    "          + f\"\\n- Past model performance: {past_perf}\")\n",
    "\n",
    "    return past_perf\n",
    "\n",
    "\n",
    "def train_model(next_row):\n",
    "\n",
    "    # preprocess data chunk by chunk\n",
    "    preprocess()\n",
    "    preprocess(source_type=\"val\")\n",
    "\n",
    "    # train model chunk by chunk\n",
    "    new_perf = train()\n",
    "\n",
    "    print(Fore.GREEN + \"\\nüî• Ran task: TRAIN MODEL:\" + Style.RESET_ALL\n",
    "          + f\"\\n- New model performance: {new_perf}\")\n",
    "\n",
    "    return new_perf\n",
    "\n",
    "\n",
    "def notify(past_perf, new_perf):\n",
    "\n",
    "    print(Fore.GREEN + f\"\\nüî• Run task: NOTIF\" + Style.RESET_ALL\n",
    "          + f\"\\n- Past performance: {past_perf}\"\n",
    "          + f\"\\n- New performance: {new_perf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    next_row = 0\n",
    "\n",
    "    # evaluate the performance of the past model\n",
    "    past_perf = eval_perf(next_row)\n",
    "\n",
    "    # retrain the model with new lines\n",
    "    new_perf = train_model(next_row)\n",
    "\n",
    "    # print results\n",
    "    notify(past_perf, new_perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INCREMENTAL **interface/workflow.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "from prefect import task, Flow\n",
    "from prefect.schedules import IntervalSchedule\n",
    "from prefect.executors import LocalDaskExecutor\n",
    "\n",
    "@task\n",
    "...\n",
    "\n",
    "\n",
    "def build_flow(schedule):\n",
    "\n",
    "    with Flow(name=\"wagonwab taxifare workflow\", schedule=schedule) as flow:\n",
    "\n",
    "        ...\n",
    "\n",
    "    return flow\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    schedule = None\n",
    "    # schedule = IntervalSchedule(interval=datetime.timedelta(minutes=300))\n",
    "\n",
    "    flow = build_flow(schedule)\n",
    "\n",
    "    flow.visualize()\n",
    "\n",
    "    flow.run()\n",
    "    # flow.executor = LocalDaskExecutor()\n",
    "    # flow.register(\"wagoncab project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üö® Set prefect backend to local server instead of cloud\n",
    "\n",
    "``` bash\n",
    "prefect backend server\n",
    "```\n",
    "\n",
    "üö® Start **Docker**, then start the prefect backend in a new shell:\n",
    "\n",
    "``` bash\n",
    "prefect server start \\\n",
    "    --postgres-port 5433 \\\n",
    "    --ui-port 8088\n",
    "```\n",
    "\n",
    "üö® Start the prefect agent in yet another shell\n",
    "\n",
    "``` bash\n",
    "prefect agent local start\n",
    "```\n",
    "\n",
    "üö® Create prefect project\n",
    "\n",
    "``` bash\n",
    "prefect create project \"wagoncab project\"\n",
    "```\n",
    "\n",
    "üëâ Run with `python -m taxifare.interface.workflow`\n",
    "\n",
    "üëâ See the results in `http://localhost:8088` or on the appropriate address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FULL **interface/workflow.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxifare.interface.main import (preprocess, train, evaluate)\n",
    "\n",
    "from colorama import Fore, Style\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from prefect import task, Flow\n",
    "from prefect.schedules import IntervalSchedule\n",
    "from prefect.executors import LocalDaskExecutor\n",
    "\n",
    "\n",
    "@task\n",
    "def eval_perf(next_row):\n",
    "\n",
    "    # evaluate latest production model on new data\n",
    "    past_perf = evaluate()\n",
    "\n",
    "    print(Fore.GREEN + \"\\nüî• Ran task: EVAL PERF:\" + Style.RESET_ALL +\n",
    "          f\"\\n- Past model performance: {past_perf}\")\n",
    "\n",
    "    return past_perf\n",
    "\n",
    "\n",
    "@task\n",
    "def train_model(next_row):\n",
    "\n",
    "    # preprocess data chunk by chunk\n",
    "    preprocess()\n",
    "    preprocess(source_type=\"val\")\n",
    "\n",
    "    # train model chunk by chunk\n",
    "    new_perf = train(stage=\"Production\")\n",
    "\n",
    "    print(Fore.GREEN + \"\\nüî• Ran task: TRAIN MODEL:\" + Style.RESET_ALL +\n",
    "          f\"\\n- New model performance: {new_perf}\")\n",
    "\n",
    "    return new_perf\n",
    "\n",
    "\n",
    "@task\n",
    "def notify(past_perf, new_perf):\n",
    "\n",
    "    print(Fore.GREEN + f\"\\nüî• Run task: NOTIF\" + Style.RESET_ALL +\n",
    "          f\"\\n- Past performance: {past_perf}\" +\n",
    "          f\"\\n- New performance: {new_perf}\")\n",
    "\n",
    "\n",
    "def build_flow(schedule):\n",
    "\n",
    "    with Flow(name=\"wagonwab taxifare workflow\", schedule=schedule) as flow:\n",
    "\n",
    "        next_row = 0\n",
    "\n",
    "        # evaluate the performance of the past model\n",
    "        past_perf = eval_perf(next_row)\n",
    "\n",
    "        # retrain the model with new lines\n",
    "        new_perf = train_model(next_row)\n",
    "\n",
    "        # print results\n",
    "        notify(past_perf, new_perf)\n",
    "\n",
    "    return flow\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # schedule = None\n",
    "    schedule = IntervalSchedule(interval=datetime.timedelta(minutes=300))\n",
    "\n",
    "    flow = build_flow(schedule)\n",
    "\n",
    "    flow.visualize()\n",
    "\n",
    "    # flow.run()\n",
    "    flow.executor = LocalDaskExecutor()\n",
    "    flow.register(\"wagoncab project\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
